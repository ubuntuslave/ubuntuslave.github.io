<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.29" />
  <meta name="author" content="Carlos Jaramillo">
  <meta name="description" content="Ph.D Candidate of Computer Science">

  
  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="/css/highlight.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  


  

  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  

  <link rel="alternate" href="" type="application/rss+xml" title="Vision 2π">
  <link rel="feed" href="" type="application/rss+xml" title="Vision 2π">

  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png">

  <link rel="canonical" href="https://ubuntuslave.github.io/project/vo_sos/">

  

  <title>Visual Odometry with a Single-Camera Stereo Omnidirectional System | Vision 2π</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Vision 2π</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      <ul class="nav navbar-nav navbar-right">
        

        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#publications_selected">
            
            <span>Publications</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#teaching">
            
            <span>Teaching</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
          </a>
        </li>

        
        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article article-project" itemscope itemtype="http://schema.org/Article">

  
<div class="article-header">
  <img src="/img/VO-SOS/noncentral_absolute_pose_registration.png" class="article-banner" itemprop="image">
  <span class="article-header-caption">Noncentral 3D pose registration for the single-camera SOS</span>
</div>



  <div class="article-container">

    <div class="pub-title">
      <h1 itemprop="name">Visual Odometry with a Single-Camera Stereo Omnidirectional System</h1>
      <span class="pub-authors" itemprop="author">&nbsp;</span>
      <span class="pull-right">
        
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Visual%20Odometry%20with%20a%20Single-Camera%20Stereo%20Omnidirectional%20System&amp;url=https%3a%2f%2fubuntuslave.github.io%2fproject%2fvo_sos%2f"
         target="_blank">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fubuntuslave.github.io%2fproject%2fvo_sos%2f"
         target="_blank">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fubuntuslave.github.io%2fproject%2fvo_sos%2f&amp;title=Visual%20Odometry%20with%20a%20Single-Camera%20Stereo%20Omnidirectional%20System"
         target="_blank">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fubuntuslave.github.io%2fproject%2fvo_sos%2f&amp;title=Visual%20Odometry%20with%20a%20Single-Camera%20Stereo%20Omnidirectional%20System"
         target="_blank">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Visual%20Odometry%20with%20a%20Single-Camera%20Stereo%20Omnidirectional%20System&amp;body=https%3a%2f%2fubuntuslave.github.io%2fproject%2fvo_sos%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


      </span>
    </div>

    

    <div class="article-style" itemprop="articleBody">
      

<p><strong>Source code</strong> and <strong>dataset</strong> coming soon because this manuscript is currently under review.</p>

<p>Demonstration video using sequences from Grand Central Terminal:</p>


<div style="position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;">
  <iframe src="//www.youtube.com/embed/c5tyHqEkKQA" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" allowfullscreen frameborder="0" title="YouTube Video"></iframe>
 </div>


<h2 id="calibration-files">Calibration Files</h2>

<p>All the calibration images and &ldquo;pickles&rdquo; can be found here:</p>

<ul>
<li><p><a href="ftp://robot:robot@134.74.16.75/datasets/calibration/real" target="_blank">real</a></p></li>

<li><p><a href="ftp://robot:robot@134.74.16.75/datasets/calibration/synthetic" target="_blank">synthetic</a></p></li>
</ul>

<p>However, to run the datasets for <strong>VO</strong>, it suffices by getting:</p>

<ul>
<li><p><a href="ftp://robot:robot@134.74.16.75/datasets/calibration/real/chessboard/gums-calibrated.pkl" target="_blank">real gums-calibrated.pkl</a></p></li>

<li><p><a href="ftp://robot:robot@134.74.16.75/datasets/calibration/synthetic/chessboard/gums-calibrated.pkl" target="_blank">synthetic gums-calibrated.pkl</a></p></li>
</ul>

<h2 id="datasets-a-name-datasets-a">Datasets<a name="datasets"></a></h2>

<p><strong>Hint</strong>: In some web browsers, clicking on the link may not work. You can try to <em>right-click</em> on the link and choose <code>&quot;Download/Save linked file as...&quot;</code></p>

<p>Each sequence has 2 sub-folders:</p>

<ul>
<li><code>omni</code> pertaining the omnistereo data</li>
<li><code>rgbd</code> pertaining the RGB-D camera data
<br /></li>
</ul>

<h3 id="remarks-about-ground-truth-data">Remarks about &ldquo;ground-truth&rdquo; data</h3>

<p><strong>When available</strong> (<strong><em>Coming soon!</em></strong>):</p>

<ol>
<li><p>Ground-truth poses obey the <a href="http://vision.in.tum.de/data/datasets/rgbd-dataset/file_formats" target="_blank">TUM format</a>, such that each line is <em>spaced-separated</em> encoding:</p>

<ul>
<li>time stamp  $t_x$  $t_y$  $t_z$  $q_x$  $q_y$  $q_z$  $q_w$</li>
</ul></li>

<li><p>For each sequence, the <code>gt_TUM.txt</code> is the <em>raw</em> ground-truth data, which was obtained from the motion capture system. Thus, these poses are given wrt our VICON mocap&rsquo;s frame, $[\rm{V}]$.</p></li>

<li><p>After running the <code>vo.py</code> for some sequence, the resulting files will be given inside the <code>results</code> subfolder within the sequence path:</p>

<ul>
<li><code>estimated_frame_poses_TUM.txt</code> has the estimated poses ${}_{[{{\rm{C}}_i}]}^{[{\rm{K}_0}]}{\bf{\tilde T}}$ of the sequence wrt the initial camera frame, $[\rm{K}_0]$.</li>
<li><code>gt_associated_frame_poses_TUM.txt</code> has the associated ground-truth poses for the registered frames. They are already transformed into the camera frame, $[\textbf{C}]$, via the appropriate <em>hand-eye transformation</em>, so that the pose is given as ${}_{[{{\rm{C}}_i}]}^{[{\rm{K}_0}]}{\bf{T}}$.
<br /></li>
</ul></li>

<li><p>For the <strong>real</strong> sequences of the RGB-D camera, the required <em>hand-eye transformation</em> is found in <a href="ftp://robot:robot@134.74.16.75/datasets/calibration/real/rgbd_hand_eye_transformation.txt" target="_blank">calibration/rgbd_hand_eye_transformation.txt</a></p></li>
</ol>

<h3 id="synthetic-sequences">Synthetic sequences</h3>

<table>
  <tr>
    <th >Name</th>
    <th ><div align="center"># Frames</div></th>
    <th >Sample</th>
  </tr>
  <tr>
    <td><a href="ftp://robot:robot@134.74.16.75/datasets/synthetic/office-0.zip" download>Office-0</a></td>
    <td><div align="center">1508</div></td>
    <td rowspan="4">
    <iframe width="280" src="https://www.youtube.com/embed/JXaaB9Qeoas?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
    </td>
  </tr>
  <tr>
    <td><a href="ftp://robot:robot@134.74.16.75/datasets/synthetic/office-1.zip" download>Office-1</a></td>
    <td><div align="center">965</div></td>
  </tr>
  <tr>
    <td><a href="ftp://robot:robot@134.74.16.75/datasets/synthetic/office-2.zip" download>Office-2</a></td>
    <td><div align="center">880</div></td>
  </tr>
  <tr>
    <td><a href="ftp://robot:robot@134.74.16.75/datasets/synthetic/office-3.zip" download>Office-3</a></td>
    <td><div align="center">1240</div></td>
  </tr>
</table>

<h3 id="real-life-sequences">Real-life sequences</h3>

<h4 id="conventional-motion">Conventional motion</h4>

<table>
<thead>
<tr>
<th>Name</th>
<th># Frames</th>
</tr>
</thead>

<tbody>
<tr>
<td><a href="ftp://dummy.zip" target="_blank">Square Small</a></td>
<td>619</td>
</tr>

<tr>
<td><a href="ftp://dummy.zip" target="_blank">Square Smooth</a></td>
<td>1325</td>
</tr>

<tr>
<td><a href="ftp://dummy.zip" target="_blank">Spinning</a></td>
<td>770</td>
</tr>

<tr>
<td><a href="ftp://dummy.zip" target="_blank">Vertical</a></td>
<td>459</td>
</tr>

<tr>
<td><a href="ftp://dummy.zip" target="_blank">Free Style</a></td>
<td>611</td>
</tr>

<tr>
<td><a href="ftp://dummy.zip" target="_blank">Hallway</a></td>
<td>5636</td>
</tr>
</tbody>
</table>

<h4 id="moving-under-special-conditions">Moving under special conditions</h4>

<table>
<thead>
<tr>
<th>Name</th>
<th># Frames</th>
</tr>
</thead>

<tbody>
<tr>
<td><a href="ftp://dummy.zip" target="_blank">Into Wall - Regular</a></td>
<td>1041</td>
</tr>

<tr>
<td><a href="ftp://dummy.zip" target="_blank">Into Wall - Slow</a></td>
<td>1400</td>
</tr>

<tr>
<td><a href="ftp://dummy.zip" target="_blank">Into Wall - Fast</a></td>
<td>896</td>
</tr>

<tr>
<td><a href="ftp://dummy.zip" target="_blank">Into Wall - Curvy</a></td>
<td>838</td>
</tr>

<tr>
<td><a href="ftp://dummy.zip" target="_blank">Into Dark - Straight</a></td>
<td>998</td>
</tr>

<tr>
<td><a href="ftp://dummy.zip" target="_blank">Into Dark - Turning</a></td>
<td>1260</td>
</tr>
</tbody>
</table>

<h4 id="moving-in-dynamic-environments">Moving in dynamic environments</h4>

<table>
<thead>
<tr>
<th>Name</th>
<th># Frames</th>
</tr>
</thead>

<tbody>
<tr>
<td><a href="ftp://dummy.zip" target="_blank">Slow Dynamic</a></td>
<td>390</td>
</tr>

<tr>
<td><a href="ftp://dummy.zip" target="_blank">Fast Dynamic</a></td>
<td>518</td>
</tr>

<tr>
<td><a href="ftp://dummy.zip" target="_blank">GCT Clock</a></td>
<td>2179</td>
</tr>

<tr>
<td><a href="ftp://dummy.zip" target="_blank">GCT Stairs</a></td>
<td>3625</td>
</tr>
</tbody>
</table>

<h4 id="static-rigs-in-dynamic-environments">Static rigs in dynamic environments</h4>

<table>
<thead>
<tr>
<th>Prox. [m]</th>
<th># People</th>
<th>File Link</th>
<th># Frames</th>
</tr>
</thead>

<tbody>
<tr>
<td>1</td>
<td>1</td>
<td><a href="ftp://dummy.zip" target="_blank">static_dynamic_1_1.zip</a></td>
<td>691</td>
</tr>

<tr>
<td>1</td>
<td>2</td>
<td><a href="ftp://dummy.zip" target="_blank">static_dynamic_1_2.zip</a></td>
<td>759</td>
</tr>

<tr>
<td>1</td>
<td>4</td>
<td><a href="ftp://dummy.zip" target="_blank">static_dynamic_1_4.zip</a></td>
<td>791</td>
</tr>

<tr>
<td>2</td>
<td>1</td>
<td><a href="ftp://dummy.zip" target="_blank">static_dynamic_2_1.zip</a></td>
<td>679</td>
</tr>

<tr>
<td>2</td>
<td>2</td>
<td><a href="ftp://dummy.zip" target="_blank">static_dynamic_2_2.zip</a></td>
<td>673</td>
</tr>

<tr>
<td>2</td>
<td>4</td>
<td><a href="ftp://dummy.zip" target="_blank">static_dynamic_2_4.zip</a></td>
<td>799</td>
</tr>

<tr>
<td>3</td>
<td>1</td>
<td><a href="ftp://dummy.zip" target="_blank">static_dynamic_3_1.zip</a></td>
<td>720</td>
</tr>

<tr>
<td>3</td>
<td>2</td>
<td><a href="ftp://dummy.zip" target="_blank">static_dynamic_3_2.zip</a></td>
<td>815</td>
</tr>

<tr>
<td>3</td>
<td>4</td>
<td><a href="ftp://dummy.zip" target="_blank">static_dynamic_3_4.zip</a></td>
<td>772</td>
</tr>

<tr>
<td>Var</td>
<td>2</td>
<td><a href="ftp://dummy.zip" target="_blank">static_dynamic_freestyle.zip</a></td>
<td>939</td>
</tr>

<tr>
<td>Var</td>
<td>Var</td>
<td><a href="ftp://dummy.zip" target="_blank">GCT_static.zip</a></td>
<td>1904</td>
</tr>
</tbody>
</table>

<h2 id="citation">Citation</h2>

<p>When using this dataset in your research, please cite:</p>

<div><p>
@ARTICLE{<a href="http://www.to_do.pdf">Jaramillo2018RAL</a>,<br/>
&nbsp; author = {<a href="http://me.vision2pi.com" target="blank">Carlos Jaramillo</a> 
and 
<a href="https://ericlyang.github.io" target="blank">Liang Yang</a> 
and 
Pablo Munoz
and 
<a href="http://yuichitaguchi.com" target="blank">Yuichi Taguchi</a>
and <a href="http://robotics.ccny.cuny.edu/" target="blank">Jizhong Xiao</a>
}, <br/> &nbsp; 
title = {Visual Odometry with a Single-Camera Stereo Omnidirectional System},<br/>&nbsp; 
journal = {TBD},<br/>
<!-- 
journal = {IEEE Robotics and Automation Letters (RA-L)},<br/> 
-->
&nbsp; year = {2018}<br/>
}
<br/>
</p></div>

<h2 id="copyright">Copyright</h2>

<div><p>
<img alt="Creative Commons License" style="border-width:0;float:left;margin-right:10px;" src="http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" />All datasets on this page are copyrighted by Carlos Jaramillo and published under the <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Creative Commons Attribution-NonCommercial-ShareAlike 3.0</a> License. 
<br/>
This means that you must attribute the work in the manner specified by the authors, you may not use this work for commercial purposes and if you alter, transform, or build upon this work, you may distribute the resulting work only under the same license.<br>
</p></div>

    </div>

  </div>
</article>

<div class="container">
  <nav>
  <ul class="pager">
    
    <li class="previous"><a href="https://ubuntuslave.github.io/project/dmt/"><span
      aria-hidden="true">&larr;</span> Direct Multichannel Tracking</a></li>
    

    
  </ul>
</nav>

</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 Carlos Jaramillo &middot; 

      Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic
      theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

