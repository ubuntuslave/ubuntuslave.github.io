<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Small UAV | Omnistereo</title>
    <link>https://ubuntuslave.github.io/tags/small-uav/</link>
      <atom:link href="https://ubuntuslave.github.io/tags/small-uav/index.xml" rel="self" type="application/rss+xml" />
    <description>Small UAV</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2019-2021 Carlos Jaramillo</copyright><lastBuildDate>Tue, 01 Oct 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ubuntuslave.github.io/img/icon.png</url>
      <title>Small UAV</title>
      <link>https://ubuntuslave.github.io/tags/small-uav/</link>
    </image>
    
    <item>
      <title>Visual Odometry with a Single-Camera Stereo Omnidirectional System</title>
      <link>https://ubuntuslave.github.io/project/vo_sos/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://ubuntuslave.github.io/project/vo_sos/</guid>
      <description>

&lt;h2 id=&#34;demonstration-video-using-sequences-from-grand-central-terminal-gct&#34;&gt;Demonstration video using sequences from Grand Central Terminal (GCT):&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/c5tyHqEkKQA&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;h2 id=&#34;source-code&#34;&gt;Source code&lt;/h2&gt;

&lt;p&gt;The demonstration code can be found at the git repository for &lt;a href=&#34;https://github.com/ubuntuslave/vo_single_camera_sos&#34; target=&#34;_blank&#34;&gt;vo_single_camera_sos&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;calibration-files&#34;&gt;Calibration Files&lt;/h2&gt;

&lt;!-- FUTURE:
All the calibration images and &#34;pickles&#34; can be found here:

- [real](ftp://robot:robot@134.74.16.75/datasets/calibration/real)

- [synthetic](ftp://robot:robot@134.74.16.75/datasets/calibration/synthetic)
 
--&gt;

&lt;h2 id=&#34;data-sets-a-name-datasets-a&#34;&gt;Data sets&lt;a name=&#34;datasets&#34;&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Each sequence has 2 sub-folders:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;omni&lt;/code&gt; pertaining the omnistereo data&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rgbd&lt;/code&gt; pertaining the RGB-D camera data
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;remarks-about-the-ground-truth-data-used-as-reference&#34;&gt;Remarks about the &amp;ldquo;ground-truth&amp;rdquo; data used as reference&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Ground-truth poses obey the &lt;a href=&#34;http://vision.in.tum.de/data/datasets/rgbd-dataset/file_formats&#34; target=&#34;_blank&#34;&gt;TUM format&lt;/a&gt;, such that each line is &lt;em&gt;spaced-separated&lt;/em&gt; encoding:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;time stamp  $t_x$  $t_y$  $t_z$  $q_x$  $q_y$  $q_z$  $q_w$&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;For each sequence, the &lt;code&gt;gt_TUM.txt&lt;/code&gt; is the &lt;em&gt;raw&lt;/em&gt; ground-truth data, which was obtained from the motion capture system. Thus, these poses are given wrt our VICON mocap&amp;rsquo;s frame, $[\rm{V}]$.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;After running the &lt;code&gt;demo_vo_*.py&lt;/code&gt; for some sequence, the resulting files will be given inside the &lt;code&gt;results&lt;/code&gt; subfolder within the sequence path:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;estimated_frame_poses_TUM.txt&lt;/code&gt; has the estimated poses ${}_{[{{\rm{C}}_i}]}^{[{\rm{K}_0}]}{\bf{\tilde T}}$ of the sequence wrt the initial camera frame, $[\rm{K}_0]$.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gt_associated_frame_poses_TUM.txt&lt;/code&gt; has the associated ground-truth poses for the registered frames. They are already transformed into the camera frame, $[\textbf{C}]$, via the appropriate &lt;em&gt;hand-eye transformation&lt;/em&gt;, so that the pose is given as ${}_{[{{\rm{C}}_i}]}^{[{\rm{K}_0}]}{\bf{T}}$.
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;For the &lt;strong&gt;real-life&lt;/strong&gt; sequences of the RGB-D camera, the required &lt;em&gt;hand-eye transformation&lt;/em&gt; can be downloaded from this link &lt;a href=&#34;https://www.dropbox.com/s/0322px08wdyirz1/rgbd_hand_eye_transformation.txt?dl=0&#34; target=&#34;_blank&#34;&gt;rgbd_hand_eye_transformation.txt&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;synthetic-sequences&#34;&gt;Synthetic sequences&lt;/h3&gt;

&lt;p&gt;To run the &lt;code&gt;demo_vo_sos.py&lt;/code&gt; script with the &lt;em&gt;synthetic&lt;/em&gt; data set, it suffices to obtain the corresponding GUMS calibration file &lt;a href=&#34;https://www.dropbox.com/s/9k8s1ah1qmgwqrc/gums-calibrated.pkl?dl=0&#34; target=&#34;_blank&#34;&gt;gums-calibrated.pkl&lt;/a&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tr&gt;
    &lt;th &gt;Name&lt;/th&gt;
    &lt;th &gt;&lt;div align=&#34;center&#34;&gt;# Frames&lt;/div&gt;&lt;/th&gt;
    &lt;th &gt;Video Sample&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/rx3n7i5n3fpsc5k/office-0.zip?dl=0&#34; download&gt;Office-0&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;div align=&#34;center&#34;&gt;1508&lt;/div&gt;&lt;/td&gt;
    &lt;td rowspan=&#34;4&#34;&gt;
    &lt;iframe width=&#34;280&#34; src=&#34;https://www.youtube.com/embed/JXaaB9Qeoas?rel=0&#34; frameborder=&#34;0&#34; allow=&#34;autoplay; encrypted-media&#34; allowfullscreen&gt;&lt;/iframe&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/ve3kkq4uoha1b46/office-1.zip?dl=0&#34; download&gt;Office-1&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;div align=&#34;center&#34;&gt;965&lt;/div&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/ore4ukmxh5j0338/office-2.zip?dl=0&#34; download&gt;Office-2&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;div align=&#34;center&#34;&gt;880&lt;/div&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/gak8cwyhookzasu/office-3.zip?dl=0&#34; download&gt;Office-3&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;div align=&#34;center&#34;&gt;1240&lt;/div&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;h3 id=&#34;real-life-sequences&#34;&gt;Real-life sequences&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;To run the &lt;code&gt;demo_vo_sos.py&lt;/code&gt; script with the &lt;em&gt;real-life&lt;/em&gt; SOS data set, it suffices to obtain the corresponding GUMS calibration file &lt;a href=&#34;https://www.dropbox.com/s/i01jl165c0mzb8n/gums-calibrated.pkl?dl=0&#34; target=&#34;_blank&#34;&gt;gums-calibrated.pkl&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;To run the &lt;code&gt;demo_vo_rgbd.py&lt;/code&gt; script with the &lt;em&gt;real-life&lt;/em&gt; RGB-D data set, the required &lt;em&gt;hand-eye transformation&lt;/em&gt; &lt;a href=&#34;https://www.dropbox.com/s/0322px08wdyirz1/rgbd_hand_eye_transformation.txt?dl=0&#34; target=&#34;_blank&#34;&gt;rgbd_hand_eye_transformation.txt&lt;/a&gt; is needed.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;conventional-motion&#34;&gt;Conventional motion&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;# Frames&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/xkxp880mxcvcj8x/square_small.zip?dl=0&#34; target=&#34;_blank&#34;&gt;Square Small&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;619&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/7xt2scl62ofwnxm/square_smooth.zip?dl=0&#34; target=&#34;_blank&#34;&gt;Square Smooth&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1325&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/nazxaamjnr6amah/spinning.zip?dl=0&#34; target=&#34;_blank&#34;&gt;Spinning&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;770&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/e3xsn9fq20fwwbr/vertical.zip?dl=0&#34; target=&#34;_blank&#34;&gt;Vertical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;459&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/ojggx0nmzg6jh9d/free_style.zip?dl=0&#34; target=&#34;_blank&#34;&gt;Free Style&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;611&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/2kttiewtv20x880/hallway.zip?dl=0&#34; target=&#34;_blank&#34;&gt;Hallway&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;5636&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;moving-under-special-conditions&#34;&gt;Moving under special conditions&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;# Frames&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/9rodx1ma02atnwu/into_wall_regular.zip?dl=0&#34; target=&#34;_blank&#34;&gt;Into Wall - Regular&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1041&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/dh1c73tsswyqzew/into_wall_slow.zip?dl=0&#34; target=&#34;_blank&#34;&gt;Into Wall - Slow&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1400&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/zymh8znjoxaf2z6/into_wall_fast.zip?dl=0&#34; target=&#34;_blank&#34;&gt;Into Wall - Fast&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;896&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/mui9v6j1rhzncl6/into_wall_curvy.zip?dl=0&#34; target=&#34;_blank&#34;&gt;Into Wall - Curvy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;838&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/xnj7e01vm2jfbkx/into_darkness_straight.zip?dl=0&#34; target=&#34;_blank&#34;&gt;Into Dark - Straight&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;998&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/bw5slevqzrwupk0/into_darkness_turning.zip?dl=0&#34; target=&#34;_blank&#34;&gt;Into Dark - Turning&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1260&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;moving-in-dynamic-environments&#34;&gt;Moving in dynamic environments&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;# Frames&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/m3q3xw747eajvtq/moving_in_slow_dynamic_environment.zip?dl=0&#34; target=&#34;_blank&#34;&gt;Slow Dynamic&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;390&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/j2p4mi8sg9h5gng/moving_in_fast_dynamic_environment.zip?dl=0&#34; target=&#34;_blank&#34;&gt;Fast Dynamic&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;518&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/ubbq4q296l669yc/GCT_clock.zip?dl=0&#34; target=&#34;_blank&#34;&gt;GCT Clock&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2179&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/16qhrqzlc4wwzvc/GCT_stairs.zip?dl=0&#34; target=&#34;_blank&#34;&gt;GCT Stairs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;3625&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;static-rigs-in-dynamic-environments&#34;&gt;Static rigs in dynamic environments&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Prox. [m]&lt;/th&gt;
&lt;th&gt;# People&lt;/th&gt;
&lt;th&gt;File Link&lt;/th&gt;
&lt;th&gt;# Frames&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/swt1az2i9rvs9ok/static_dynamic_1_1.zip?dl=0&#34; target=&#34;_blank&#34;&gt;static_dynamic_1_1.zip&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;691&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/chh2oh21ufg1a26/static_dynamic_1_2.zip?dl=0&#34; target=&#34;_blank&#34;&gt;static_dynamic_1_2.zip&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;759&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/6bco2rtpncqrdsl/static_dynamic_1_4.zip?dl=0&#34; target=&#34;_blank&#34;&gt;static_dynamic_1_4.zip&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;791&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/m2u0qx1nsjz3v07/static_dynamic_2_1.zip?dl=0&#34; target=&#34;_blank&#34;&gt;static_dynamic_2_1.zip&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;679&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/b0viyankjrh81tq/static_dynamic_2_2.zip?dl=0&#34; target=&#34;_blank&#34;&gt;static_dynamic_2_2.zip&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;673&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/yw0y63tslvu2zff/static_dynamic_2_4.zip?dl=0&#34; target=&#34;_blank&#34;&gt;static_dynamic_2_4.zip&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;799&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/pkguohcliqd120p/static_dynamic_3_1.zip?dl=0&#34; target=&#34;_blank&#34;&gt;static_dynamic_3_1.zip&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;720&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/d2d062sl8vo1wfp/static_dynamic_3_2.zip?dl=0&#34; target=&#34;_blank&#34;&gt;static_dynamic_3_2.zip&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;815&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/cnr0antcvt5tv3a/static_dynamic_3_4.zip?dl=0&#34; target=&#34;_blank&#34;&gt;static_dynamic_3_4.zip&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;772&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Var&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/kamzqbkgpoey0p3/static_dynamic_freestyle.zip?dl=0&#34; target=&#34;_blank&#34;&gt;static_dynamic_freestyle.zip&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;939&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Var&lt;/td&gt;
&lt;td&gt;Var&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.dropbox.com/s/8666co2qu4a61en/GCT_static.zip?dl=0&#34; target=&#34;_blank&#34;&gt;GCT_static.zip&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;1904&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;

&lt;p&gt;When using this dataset in your research, please cite:&lt;/p&gt;

&lt;div&gt;&lt;p&gt;
@ARTICLE{&lt;a href=&#34;http://dx.doi.org/10.1007/s00138-019-01041-9&#34;&gt;Jaramillo2019MVAP&lt;/a&gt;,&lt;br/&gt;
&amp;nbsp; author = {&lt;a href=&#34;http://ubuntuslave.github.io&#34; target=&#34;blank&#34;&gt;Carlos Jaramillo&lt;/a&gt; 
and 
&lt;a href=&#34;https://ericlyang.github.io&#34; target=&#34;blank&#34;&gt;Liang Yang&lt;/a&gt; 
and 
Pablo Munoz
and 
&lt;a href=&#34;http://yuichitaguchi.com&#34; target=&#34;blank&#34;&gt;Yuichi Taguchi&lt;/a&gt;
and &lt;a href=&#34;http://robotics.ccny.cuny.edu/&#34; target=&#34;blank&#34;&gt;Jizhong Xiao&lt;/a&gt;
}, &lt;br/&gt; &amp;nbsp; 
title = {Visual Odometry with a Single-Camera Stereo Omnidirectional System},&lt;br/&gt;&amp;nbsp; 
journal = {Springer Machine Vision and Applications (MVAP)},&lt;br/&gt; 
&amp;nbsp; year = {2019}&lt;br/&gt;
}
&lt;br/&gt;
&lt;/p&gt;&lt;/div&gt;

&lt;h2 id=&#34;copyright&#34;&gt;Copyright&lt;/h2&gt;

&lt;div&gt;&lt;p&gt;
&lt;img alt=&#34;Creative Commons License&#34; style=&#34;border-width:0;float:left;margin-right:10px;&#34; src=&#34;http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png&#34; /&gt;All datasets on this page are copyrighted by Carlos Jaramillo and published under the &lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/3.0/&#34;&gt;Creative Commons Attribution-NonCommercial-ShareAlike 3.0&lt;/a&gt; License. 
&lt;br/&gt;
This means that you must attribute the work in the manner specified by the authors, you may not use this work for commercial purposes and if you alter, transform, or build upon this work, you may distribute the resulting work only under the same license.&lt;br&gt;
&lt;/p&gt;&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Design and Analysis of a Single-Camera Omnistereo Sensor for Quadrotor Micro Aerial Vehicles (MAVs)</title>
      <link>https://ubuntuslave.github.io/publication/2016-sensors-omnistereo_sensor/</link>
      <pubDate>Sat, 06 Feb 2016 00:00:00 +0000</pubDate>
      <guid>https://ubuntuslave.github.io/publication/2016-sensors-omnistereo_sensor/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;graphical_representation_of_the_paper-white_bg.png&#34; alt=&#34;Graphical representation of the article&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Single-Camera Omni-Stereo Vision System for 3D Perception of Micro Aerial Vehicles (MAVs)</title>
      <link>https://ubuntuslave.github.io/publication/2013-iciea-omnistereo/</link>
      <pubDate>Wed, 19 Jun 2013 00:00:00 +0000</pubDate>
      <guid>https://ubuntuslave.github.io/publication/2013-iciea-omnistereo/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
